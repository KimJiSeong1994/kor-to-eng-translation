{"cells":[{"cell_type":"markdown","metadata":{"id":"jUC_vYJGOA6c"},"source":["# Training on GPU"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25456,"status":"ok","timestamp":1612164820706,"user":{"displayName":"hansol park","photoUrl":"","userId":"13314081940074376337"},"user_tz":-540},"id":"jzhqKtLEOd4X","outputId":"c457b413-c4c6-47bd-d854-252be487da68"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","config\teval.py  README.md  train_gpu.ipynb  transformers\n","data\tlib\t results    train.py\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir('/content/drive/MyDrive/Programming/Projects/kor-to-eng-translation')\n","!ls"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30974,"status":"ok","timestamp":1612164826228,"user":{"displayName":"hansol park","photoUrl":"","userId":"13314081940074376337"},"user_tz":-540},"id":"LUB_1ClxQfe4","outputId":"538cdab7-10ce-4b36-c365-63f3929ffb4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n","\u001b[?25hCollecting tweepy\u003e=3.7.0\n","  Downloading https://files.pythonhosted.org/packages/67/c3/6bed87f3b1e5ed2f34bd58bf7978e308c86e255193916be76e5a5ce5dfca/tweepy-3.10.0-py2.py3-none-any.whl\n","Collecting JPype1\u003e=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/af/93f92b38ec1ff3091cd38982ed19cea2800fefb609b5801c41fc43c0781e/JPype1-1.2.1-cp36-cp36m-manylinux2010_x86_64.whl (457kB)\n","\u001b[K     |████████████████████████████████| 460kB 57.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.5)\n","Requirement already satisfied: lxml\u003e=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Collecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 14.5MB/s \n","\u001b[?25hRequirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy\u003e=3.7.0-\u003ekonlpy) (1.3.0)\n","Requirement already satisfied: six\u003e=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy\u003e=3.7.0-\u003ekonlpy) (1.15.0)\n","Requirement already satisfied: requests[socks]\u003e=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy\u003e=3.7.0-\u003ekonlpy) (2.23.0)\n","Requirement already satisfied: typing-extensions; python_version \u003c \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1\u003e=0.7.0-\u003ekonlpy) (3.7.4.3)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003etweepy\u003e=3.7.0-\u003ekonlpy) (3.1.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]\u003e=2.11.1-\u003etweepy\u003e=3.7.0-\u003ekonlpy) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]\u003e=2.11.1-\u003etweepy\u003e=3.7.0-\u003ekonlpy) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]\u003e=2.11.1-\u003etweepy\u003e=3.7.0-\u003ekonlpy) (2020.12.5)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]\u003e=2.11.1-\u003etweepy\u003e=3.7.0-\u003ekonlpy) (3.0.4)\n","Requirement already satisfied: PySocks!=1.5.7,\u003e=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]\u003e=2.11.1-\u003etweepy\u003e=3.7.0-\u003ekonlpy) (1.7.1)\n","Installing collected packages: tweepy, JPype1, colorama, beautifulsoup4, konlpy\n","  Found existing installation: tweepy 3.6.0\n","    Uninstalling tweepy-3.6.0:\n","      Successfully uninstalled tweepy-3.6.0\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.10.0\n"]}],"source":["!pip install konlpy "]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":34114,"status":"ok","timestamp":1612164829373,"user":{"displayName":"hansol park","photoUrl":"","userId":"13314081940074376337"},"user_tz":-540},"id":"3jxikdoQUL27"},"outputs":[],"source":["#@title Transformer layers { display-mode: \"form\" }\n","\"\"\"\n","Word Embedding \u0026 Positional Embedding\n","\"\"\"\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","#####################################\n","\n","class Affine(nn.Module):\n","    \"\"\" Fully Connected Layer \"\"\"\n","\n","    def __init__(self, i_dim, o_dim):\n","        super(Affine, self).__init__()\n","        self.W = nn.Parameter(nn.init.xavier_normal_(torch.empty(i_dim, o_dim)))\n","        self.b = nn.Parameter(nn.init.uniform_(torch.empty(o_dim)))\n","\n","    def forward(self, inp, linear=False):\n","        \"\"\"\n","        Args:\n","            inp ([Tensor]): [bsize, maxlen, emb_size]\n","            linear (bool): bool\n","        Returns: [bsize, maxlen, hid_size]\n","        \"\"\"\n","        # [bsize, maxlen, emb_size] * [emb_size, hid_size]\n","        if linear:\n","            return torch.mm(inp, self.W) + self.b\n","        return F.relu((torch.matmul(inp, self.W)) + self.b)\n","\n","\n","class NormLayer(nn.Module):\n","    def __init__(self, d_inp, eps=1e-05):\n","        super(NormLayer, self).__init__()\n","        self.eps = eps\n","        self.gamma = Affine(d_inp, d_inp)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Args:\n","            x (Tensor): [bsize, maxlen, dim]\n","        Returns: [bsize, maxlen, dim]\n","        \"\"\"\n","        return self.gamma((x - torch.mean(x)) / torch.sqrt(torch.var(x) + self.eps))\n","\n","\n","class Attention(nn.Module):\n","    # 기존에 만들었던거 참조해서 만들기\n","    \"\"\" Scaled Dot-product Attention \"\"\"\n","\n","    def __init__(self, d_inp, d_q, d_k, d_v):\n","        super(Attention, self).__init__()\n","        self.Wq = Affine(d_inp, d_q)\n","        self.Wk = Affine(d_inp, d_k)\n","        self.Wv = Affine(d_inp, d_v)\n","\n","    def forward(self, query, key, value, mask=None):\n","        \"\"\"\n","        Args:\n","            query (): [bsize, maxlen, d_m]\n","            key (): [bsize, maxlen, d_m]\n","            value (): [bsize, maxlen, d_m]\n","            mask (): [bsize, ?, maxlen]\n","        Returns:  [bsize, maxlen, d_k]\n","        \"\"\"\n","        # [bsize, maxlen, d_k]\n","        wq = self.Wq(query)\n","        wk = self.Wk(key)\n","        wv = self.Wv(value)\n","        # attention distribution\n","        # Energy [bsize, maxlen, d_q] @ [bsize, d_k, maxlen] = [bsize, maxlen, maxlen]\n","        attn_dstr = torch.bmm(wq, torch.transpose(wk, 1, 2)) / torch.sqrt(torch.FloatTensor([key.size(-1)]))\n","        if mask is not None:\n","            attn_dstr = attn_dstr.masked_fill(mask == 0, -1e10)\n","        attn_dstr = F.softmax(attn_dstr, dim=2)\n","        # [bsize, maxlen, maxlen] @ [bsize, maxlen, d_v] = [bsize, maxlen, d_v]\n","        attn = torch.bmm(attn_dstr, wv)\n","        return attn\n","\n","\n","##############################\n","\n","class PositionalEmbedding(nn.Module):\n","    \"\"\"\n","    Basic Word Embedding\n","    Let the model learn sequence information with positional-encoding\n","    \"\"\"\n","\n","    def __init__(self, vocab_size, emb_dim):\n","        super(PositionalEmbedding, self).__init__()\n","        # self.affine = Affine(vocab_size, emb_dim)\n","        self.embedding = WordEmbedding(vocab_size, emb_dim)\n","        self.dropout = nn.Dropout(p=0.1)\n","\n","    def forward(self, inp):\n","        \"\"\"\n","        Args:\n","            x (Tensor): [bsize, maxlen, emb_dim]\n","        Returns: [bsize, maxlen, emb_dim]\n","        \"\"\"\n","        \"\"\"\n","        임베딩값 dim 값으로 나눠주는거 놓침 \n","        \"\"\"\n","        # [bsize, maxlen, emb_dim]\n","        out = self.embedding(inp)\n","        # [bsize, maxlen, emb_dim]\n","        pe_rst = positional_embedding(out.size(0), out.size(1), out.size(2))\n","        # [bsize, maxlen, emb_dim]\n","        return self.dropout(out + pe_rst)\n","\n","\n","class WordEmbedding(nn.Module):\n","    def __init__(self, vocab_size, emb_dim):\n","        super(WordEmbedding, self).__init__()\n","        # self.affine = Affine(vocab_size, emb_dim)\n","        self.embedding = nn.Embedding(vocab_size, emb_dim)\n","\n","    def forward(self, inp):\n","        scale = torch.sqrt(torch.FloatTensor([inp.size(0)]))\n","        out = self.embedding(inp) / scale\n","        return out\n","\n","\n","def positional_embedding(bsize, maxlen, d_m):\n","    out = torch.stack(\n","        [positional_encoding(maxlen, d_m)] * bsize\n","    )\n","    return out\n","\n","\n","def positional_encoding(maxlen, dim):\n","    \"\"\" Give unique value by position and dimension \"\"\"\n","\n","    def term(i):\n","        return 1 / (10000 ** (2 * (i // 2) / dim))\n","\n","    pos = torch.as_tensor(np.arange(maxlen))\n","    dims = np.arange(dim)\n","    dims = torch.tensor(list(map(lambda x: term(x), dims)))\n","    # [maxlen, dim]\n","    pe_val = pos.unsqueeze(1) * dims\n","    # [maxlen, dim]\n","    pe = torch.zeros(maxlen, dim)\n","    pe[:, 0::2] = torch.sin(pe_val[:, 0::2])\n","    pe[:, 1::2] = torch.cos(pe_val[:, 0::2])\n","    return pe\n","\n","\n","########################\n","\n","\n","class MultiHeadAttention(nn.Module):\n","    \"\"\" Multi-head Attention + Add\u0026Norm \"\"\"\n","\n","    def __init__(self, d_m, n_head=4):\n","        super(MultiHeadAttention, self).__init__()\n","        assert d_m % n_head == 0\n","        d_k = int(d_m / n_head)\n","        self.head = n_head\n","        self.Wo = Affine(d_m, d_m)\n","        self.attn_layers = nn.ModuleList(\n","            [Attention(d_m, d_k, d_k, d_k) for _ in range(n_head)])\n","        self.dropout = nn.Dropout(p=0.01)\n","        self.addnorm = NormLayer(d_m)\n","\n","    def forward(self, query, key, value, mask):\n","        \"\"\"\n","        Args:\n","            query (Tensor): [batch size, maxlen, d_m]\n","            key (Tensor): [batch size, maxlen, d_m]\n","            value (Tensor): [batch size, maxlen, d_m]\n","            mask (Tensor): [batch size, ?, maxlen]\n","        Returns: [batch size, maxlen, d_m]\n","        \"\"\"\n","        heads = []\n","        for layer in self.attn_layers:  # TODO 이게 맞는지 확인\n","            # head : [batch size, maxlen, d_k]\n","            head = layer(query, key, value, mask)\n","            heads.append(head)\n","        # [batch size, maxlen, d_k*head]\n","        multi_attn = self.Wo(torch.cat(heads, dim=2))\n","        multi_attn = self.dropout(multi_attn)\n","\n","        # [batch size, maxlen, d_k*head]\n","        resdl = query + multi_attn\n","        # [batch size, maxlen, d_k*head]\n","        out = self.addnorm(resdl)\n","        return out\n","\n","\n","class PositionWiseFFLayer(nn.Module):\n","    \"\"\" Position-wise FeedForward + Add\u0026Norm \"\"\"\n","\n","    def __init__(self, d_m, d_ff):\n","        super(PositionWiseFFLayer, self).__init__()\n","        self.W1 = Affine(d_m, d_ff)\n","        self.W2 = Affine(d_ff, d_m)\n","        self.dropout = nn.Dropout(p=0.01)\n","        self.addnorm = NormLayer(d_m)\n","\n","    def forward(self, inp):\n","        \"\"\"\n","        Args:\n","            inp (Tensor): [batch size, maxlen, d_m]\n","        Returns: [batch size, maxlen, d_m]\n","        \"\"\"\n","        # [batch size, maxlen, d_ff]\n","        out = torch.relu(self.W1(inp))\n","        # [batch size, maxlen, d_m]\n","        out = self.W2(out)\n","        resdl = inp + self.dropout(out)\n","        # [batch size, maxlen, d_m]\n","        out = self.addnorm(resdl)\n","        return out\n","\n","#######################\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, d_m, d_ff):\n","        super(Encoder, self).__init__()\n","        self.multi_attn = MultiHeadAttention(d_m)\n","        self.pw_ff = PositionWiseFFLayer(d_m, d_ff)\n","\n","    def forward(self, inp, mask):\n","        \"\"\"\n","        Args:\n","            inp (Tensor): [batch size, maxlen, d_m]\n","            mask (Tensor): [batch size, 1, maxlen]\n","        Returns: [batch size, maxlen, d_m]\n","        \"\"\"\n","        # Sub-layer 1\n","        out = self.multi_attn(inp, inp, inp, mask)\n","        # Sub-layer 2\n","        out = self.pw_ff(out)\n","        return out\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, inp_dim, d_m, d_ff):\n","        super(Decoder, self).__init__()\n","        self.multi_attn = MultiHeadAttention(d_m, inp_dim)\n","        self.multi_attn = MultiHeadAttention(d_m, inp_dim)\n","        self.pw_ff = PositionWiseFFLayer(d_m, d_ff)\n","\n","    def forward(self, inp, enc_out, src_mask, trg_mask):\n","        \"\"\"\n","        Args:\n","            inp (Tensor): [batch size, maxlen, d_m]\n","            enc_out (Tensor): [batch size, maxlen, d_m]\n","            src_mask (Tensor): [batch size, 1, maxlen]\n","            trg_mask (Tensor): [batch size, maxlen, maxlen]\n","        Returns:\n","        \"\"\"\n","        # Sub-layer 1\n","        # [batch size, maxlen, d_m]\n","        out = self.multi_attn(inp, inp, inp, trg_mask)  # masked self attention\n","        # Sub-layer 2\n","        # [batch size, maxlen, d_m]\n","        out = self.multi_attn(out, enc_out, enc_out, src_mask)  # encoder-decoder attention\n","        # Sub-layer 3\n","        # [batch size, maxlen, d_m]\n","        out = self.pw_ff(out)\n","        return out\n","\n","\n","\n","##############################\n","\n","\n","class BatchNorm(nn.Module):\n","    def __init__(self, num_feature, eps=0.01, momentum=0.9):  # maxlen\n","        super(BatchNorm, self).__init__()\n","        shape = 1, 1, num_feature  # (batch, maxlen, hidd), norm target is hidd\n","        self.eps = eps\n","        self.momentum = momentum\n","        self.gamma = nn.Parameter(nn.init.xavier_normal_(torch.empty(shape)))\n","        self.beta = nn.Parameter(nn.init.xavier_normal_(torch.empty(shape)))\n","\n","        # The variables that are not model parameters are initialized to 0\n","        self.moving_mean = torch.zeros(shape)\n","        self.moving_var = torch.zeros(shape)\n","\n","    def update_movings(self, mean, var):\n","        self.moving_mean = self.momentum * self.moving_mean + (1 - self.momentum) * mean\n","        self.moving_var = self.momentum * self.moving_var + (1 - self.momentum) * var\n","\n","    def forward(self, batch):\n","        # If `X` is not on the main memory, copy `moving_mean` and\n","        # `moving_var` to the device where `X` is located\n","        if not torch.is_grad_enabled():\n","            self.moving_mean = self.moving_mean.to(batch.device)\n","            self.moving_var = self.moving_var.to(batch.device)\n","            normed = (batch - self.moving_mean) / torch.sqrt(self.moving_var + self.eps)\n","        else:\n","            mean = torch.mean(batch, dim=(0, 1), keepdim=True)\n","            var = torch.var(batch, dim=(0, 1), keepdim=True)\n","            normed = (batch - mean) / torch.sqrt(var + self.eps)\n","            self.update_movings(mean, var)\n","        new_batch = self.gamma * normed + self.beta\n","        return new_batch\n","\n","\n","class LabelSmoothingLoss(nn.NLLLoss):\n","    def __init__(self, a: float = 0.01, reduction='mean', ignore_index=-100):\n","        super(LabelSmoothingLoss, self).__init__()\n","        self.a = a\n","        self.reduction = reduction\n","        self.ignore_index = ignore_index\n","\n","    @torch.no_grad()\n","    def forward(self, pred, trg):\n","        K = pred.size(-1)  # class number\n","        trg_idx = trg != self.ignore_index  # identify not PAD\n","        trg = trg[trg_idx]\n","\n","        log_pred = F.log_softmax(pred[trg_idx], dim=-1)\n","        loss = -torch.sum(log_pred, dim=-1)\n","        if self.reduction == 'mean':\n","            loss = torch.mean(loss)\n","        elif self.reduction == 'sum':\n","            loss = torch.sum(loss)\n","        nll_loss = F.nll_loss(log_pred, trg, reduction=self.reduction)\n","        loss = nll_loss * (1 - self.a) + self.a * (loss / K)\n","        return loss.mean()\n","\n","\n","class CrossEntropyLoss(nn.Module):\n","    def __init__(self, a: float = 0.01, reduction='mean', ignore_index=-100):\n","        super(CrossEntropyLoss, self).__init__()\n","        self.a = a\n","        self.reduction = reduction\n","        self.ignore_index = ignore_index\n","\n","    @torch.no_grad()\n","    def forward(self, pred, trg):\n","        pass\n","\n","\n","\n","###################\n","\n","\n","class Transformer(nn.Module):\n","    \"\"\" Assemble layers to build Transformer \"\"\"\n","\n","    def __init__(self, d_m, inp_vocab_size, out_vocab_size, d_ff, n=3):\n","        super(Transformer, self).__init__()\n","        self.inp_emb = PositionalEmbedding(inp_vocab_size, d_m)\n","        self.out_emb = PositionalEmbedding(out_vocab_size, d_m)\n","        self.enc_layers = nn.ModuleList(\n","            [Encoder(d_m, d_ff) for _ in range(n)])\n","        self.dec_layers = nn.ModuleList(\n","            [Decoder(d_m, d_m, d_ff) for _ in range(n)])\n","        self.affine = Affine(d_m, out_vocab_size)\n","        self.n = n\n","\n","    def encoder(self, inp_batch, src_mask):\n","        \"\"\"\n","        Args:\n","            inp_batch (Tensor): [batch size, maxlen]\n","            src_mask (Tensor): [bsize, 1, maxlen]\n","        Returns: [batch size, maxlen, d_m]\n","        \"\"\"\n","        # [batch size, maxlen, d_m]\n","        i_emb = self.inp_emb(inp_batch)\n","        # Encoder\n","        enc = i_emb\n","        for layer in self.enc_layers:\n","            # [batch size, maxlen, d_m]\n","            enc = layer(enc, src_mask)\n","        return enc\n","\n","    def forward(self, inp_batch, out_batch):\n","        \"\"\"\n","        Args:\n","            inp_batch (Tensor): [batch size, maxlen]\n","            out_batch (Tensor): [batch size, maxlen]\n","        Returns: [batch size, maxlen, vocab_size]\n","        \"\"\"\n","        # Encoder\n","        src_mask = mask_not_pad(inp_batch)\n","        # [batch size, maxlen, d_m]\n","        enc = self.encoder(inp_batch, src_mask)\n","\n","        # Decoder\n","        trg_mask = mask_get_dec(out_batch)\n","        # [batch size, maxlen, d_m]\n","        o_emb = self.out_emb(out_batch)\n","        dec = o_emb\n","        for layer in self.dec_layers:\n","            # [batch size, maxlen, d_m]\n","            dec = layer(dec, enc, src_mask, trg_mask)\n","        # [batch size, maxlen, vocab_size]\n","        rst = F.log_softmax(self.affine(dec), dim=2)\n","        return rst\n","\n","    @torch.no_grad()\n","    def predict(self, inp_batch):\n","        \"\"\"\n","        Args:\n","            inp_batch (Tensor): [batch size, maxlen]\n","        Returns: [batch size, maxlen, vocab_size]\n","        \"\"\"\n","        src_mask = mask_not_pad(inp_batch)\n","        # [batch size, maxlen, d_m]\n","        enc = self.encoder(inp_batch, src_mask)\n","        # [batch size, maxlen, d_m] @ [d_m, vocab_size]\n","        # =\u003e [batch size, maxlen, vocab_size]\n","        rst = F.log_softmax(self.affine(enc), dim=2)\n","        rst = torch.argmax(rst, dim=-1).tolist()\n","        return rst\n","\n","\n","def mask_not_pad(x):\n","    \"\"\"\n","    Mark True at PAD\n","    Args:\n","        x (Tensor): [bsize, maxlen] with word idx\n","    Returns: [bsize, 1, maxlen] with bool if idx \u003c=0, True\n","    \"\"\"\n","    return (x \u003e 0).unsqueeze(1)\n","\n","\n","def mask_get_dec(x):\n","    \"\"\"\n","    Mark dec right sequence\n","    Args:\n","        x (Tensor): [bsize, maxlen] with bool\n","    Returns: [bsize, maxlen, maxlen] with bool\n","    \"\"\"\n","    # [bsize, 1, maxlen]\n","    pad_masked = mask_not_pad(x)\n","    # [maxlen, maxlen]\n","    seq_masked = torch.tril(torch.ones(x.size(1), x.size(1)))\n","    # [bsize, maxlen, maxlen]\n","    seq_masked = seq_masked.unsqueeze(0).repeat(x.size(0), 1, 1)\n","    # [bsize, maxlen, maxlen]\n","    masked = seq_masked.masked_fill(pad_masked == 0, 0)\n","    return masked\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":473},"executionInfo":{"elapsed":38408,"status":"error","timestamp":1612164833670,"user":{"displayName":"hansol park","photoUrl":"","userId":"13314081940074376337"},"user_tz":-540},"id":"idv2mbG7OZrV"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive/Programming/Projects/kor-to-eng-translation\n","['.git', '.gitignore', '.gitmodules', '.idea', 'README.md', 'config', 'eval.py', 'lib', 'results', 'train.py', 'transformers', 'train_gpu.ipynb', 'data']\n"]},{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-25-d716e4765d3e\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# load \u0026 preprocess corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mko_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ko_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ko'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 24\u001b[0;31m \u001b[0men_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_en_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# load vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Programming/Projects/kor-to-eng-translation/lib/util.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 29\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/korean-english-park.train2/korean-english-park.train.en'"]}],"source":["from lib.util import Config\n","from lib.kor2eng import LangTranslator\n","from lib.util import load_data\n","from lib.data_preprocess import Vocab, preprocessor\n","from lib.model.seq2seq import BiLSTMSeq2Seq\n","# from transformers.lib.model.transformer import Transformer\n","\n","import os\n","cwd = os.getcwd()\n","print(cwd)\n","\n","import os\n","arr = os.listdir()\n","print(arr)\n","\n","# load configs\n","dconf_path = 'config/data.json'\n","mconf_path = 'config/lm.json'\n","dconf = Config(dconf_path)\n","mconf = Config(mconf_path)\n","\n","# load \u0026 preprocess corpus\n","ko_corpus = preprocessor(load_data(dconf.train_ko_path), lang='ko')\n","en_corpus = preprocessor(load_data(dconf.train_en_path), lang='en')\n","\n","# load vocab\n","ko_vocab = Vocab(dconf.min_cnt)\n","en_vocab = Vocab(dconf.min_cnt)\n","ko_vocab.load(ko_corpus)\n","en_vocab.load(en_corpus)\n","\n","# define lm model\n","if mconf.model == 'seq2seq':\n","    model = BiLSTMSeq2Seq(len(ko_vocab) + 1, len(en_vocab) + 1,\n","                               mconf.emb_dim, mconf.d_m)\n","if mconf.model == 'transformer':\n","    model = Transformer(mconf.d_m, len(ko_vocab) + 1, len(en_vocab) + 1,\n","                        mconf.d_m*4, n_layer=3)\n","\n","# load translator and train\n","lm = LangTranslator(model, ko_vocab, en_vocab, dconf, mconf)\n","lm.train(ko_corpus, ko_corpus)\n","\n","# save model\n","lm.save('trained.pth')\n","mconf.save(mconf_path)\n","\n","test = ['또 하나 필요한 것은 훌륭한 영어 실력이다.',\n","        '경찰은 월요일 밤 집무실을 찾아 증거를 압수했다.']\n","print(lm.translate(test))"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMI74nDrCp9VnYgc2w+GcOA","machine_shape":"hm","name":"train_gpu.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}